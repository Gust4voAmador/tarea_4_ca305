{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "127e428b-b2a6-48db-bd06-9e4bb4cad419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def kernel_sigmoid(z):\n",
    "    '''\n",
    "    Función signomide o función logística, la cual tiene dominio en los \n",
    "    números reales e imágenes entre cero y uno.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    z (int): Cualqueir número real.\n",
    "    \n",
    "    Returns\n",
    "    ------    \n",
    "    (int): Número entre cero y uno.\n",
    "    '''    \n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea5314f0-9e62-4121-8425-9516d47569dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(W, b, X, y):\n",
    "    \"\"\"\n",
    "    Propagación hacia adelante, es dericr, calcula las predicciones del modelo y el costo asociado para un \n",
    "    conjunto dado de datos de entrada, utilizando los parámetros indicados W como peso y b como el sesgo.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    W (numpy.ndarray) : Vector de pesos de la regresión logística.\n",
    "        \n",
    "    b (float) : Sesgo de la regresión logística.\n",
    "        \n",
    "    X (numpy.ndarray): \n",
    "        Parámetro con la matriz de la variables caracteristicas. Cada fila representa una observacion, \n",
    "        y cada columna representa una variable (característica), es utilizado para trianing.\n",
    "        \n",
    "    y (numpy.ndarray) : Array de numpy (columna) con las estiquestas reales de los datos.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    A (numpy.ndarray): Array de numpy con las predicciones del modelo. Cada elemento del array representa la probabilidad\n",
    "    de que el ejemplo correspondiente pertenezca a la clase positiva (una de las dos etiquetas reales).\n",
    "\n",
    "        \n",
    "    cost (float) : Valor de la función de costo calculado.\n",
    "    \"\"\"  \n",
    "    \n",
    "    #obtener el número de filas de los datos de training\n",
    "    data_number = X.shape[0]\n",
    "    # Calcula para cada entrada de X un combinación linea con los parámetros de la regresión W y b\n",
    "    Z = np.dot(W, X.T) + b\n",
    "    # Aplicar la función sigmoide a cada valor de z para obtener las predicciones\n",
    "    A = kernel_sigmoid(Z)\n",
    "    # Calculo de la funcion de costos de la regresion. Sirve para medir que tan equivocado estás\n",
    "    cost = (- 1 / data_number) * np.sum(y * np.log(A) + (1 - y) * (np.log(1 - A)))\n",
    "    #Retorna las predicciones del modelo y el costo asociado con esas predicciones. \n",
    "    return A, cost\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e079a2e9-a493-4f75-bf3f-9a33825fc10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(X, A, y):\n",
    "    \n",
    "    #obtener el número de filas de los datos de training\n",
    "    data_number = X.shape[0]\n",
    "    # los gradites indica la dirección y la magnitud en la que debemos ajustar los parámetros\n",
    "    #Calcula el gradiente del array W (pesos) para minimizar el costo\n",
    "    dW = (1 / data_number) * np.dot((A - y), X)\n",
    "    #Calcula el gradiente del array b (sesgo) para minimizar el costo\n",
    "    db = (1 / data_number) * np.sum(A - y)\n",
    "    #Devuelve los gradites respectivos\n",
    "    return dW, db\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3633d23-8142-4bd6-84d7-eeedaaff39e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(W, b, X, y, num_iterations, learning_rate):\n",
    "    \"\"\"\n",
    "    la función optimize ajusta iterativamente los parámetros del modelo utilizando el gradiente \n",
    "    descendente para minimizar el costo. Guardar los costos cada 100 iteraciones permite monitorear\n",
    "    el proceso de entrenamiento y asegurarse de que el modelo está aprendiendo correctamente.\n",
    "    \"\"\"\n",
    "    \n",
    "    #crea lista para guardar los costos.\n",
    "    costs = []\n",
    "\n",
    "    # For para ejecutar las actualizaciones segun el número de iteraciones especificado\n",
    "    for i in range(num_iterations):\n",
    "        #se ejecuta el metodo de propagacion hacia adelante con los parámetros ingresados\n",
    "        A, cost = forward_propagation(W, b, X, y)\n",
    "        #se ejecuta el metodo de propagacion hacia atras con los parámetros ingresados\n",
    "        dW, db = backward_propagation(X, A, y)\n",
    "        #Se modifica W con la tasa de aprendizaje indicada y el gradiente de W\n",
    "        W = W - learning_rate * dW\n",
    "        #Se modifica b con la tasa de aprendizaje indicada y el gradiente de b\n",
    "        b = b - learning_rate * db\n",
    "        #si la iteración es módulo 100 se guarda en la lista costs definida fura del for\n",
    "        #Esto para ver con se va comportando los costos y si van disminuyendo o si se estancó.\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "\n",
    "    #Diccionario para guardar los valores finales de los parámetros\n",
    "    params = {\n",
    "        \"W\": W, \n",
    "        \"b\": b\n",
    "    }\n",
    "    #Diccionario para guardar los valores finales de los gradientes\n",
    "    gradients = {\n",
    "        \"dW\": dW,\n",
    "        \"db\": db\n",
    "    }\n",
    "    #Devolver los diccionarios de los parámetros, gradientes y la lista de la evolución de los costos.\n",
    "    return params, gradients, costs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d67eab4-9164-437a-9ef1-546cc21afc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(W, b, X):\n",
    "    \n",
    "    #obtener el número de filas de los datos de training\n",
    "    data_number = X.shape[0]\n",
    "     #Inicializa un array a cero donde van a estar la predicciónes.\n",
    "    y_prediction = np.zeros((1, data_number))\n",
    "    # Calcula para cada entrada de X un combinación linea con los parámetros de la regresión W y b\n",
    "    Z = np.dot(W, X.T) + b\n",
    "    #aplica la función sigmoide en Z calculado anteriormente, obteniendo así las \"activaciones\" para cada entrada.\n",
    "    A = kernel_sigmoid(Z)\n",
    "    #for que recorre las activaciones de Z para generar las respectivas predicciones\n",
    "    for i in range(A.shape[1]):\n",
    "        #Es 1 cuando la activación es mayor que 0.5, sino se le asígna 0.\n",
    "        y_prediction[0, i] = 1 if A[0, i] > 0.5 else 0\n",
    "        \n",
    "    #Retorna todas las predicciones\n",
    "    return y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bcaff9-e949-425a-bb3f-9d244c85cedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_regresion_logistico(X_train, y_train, X_val, y_val, num_iterations=2000, learning_rate=0.5):\n",
    "    dimensions = X_train.shape[1]\n",
    "    W = np.zeros(shape=(1, dimensions))\n",
    "    b = 0\n",
    "    params, gradients, costs = optimize(W, b, X_train, y_train, num_iterations, learning_rate)\n",
    "    W = params[\"W\"]\n",
    "    b = params[\"b\"]\n",
    "    y_prediction_validation = predict(W, b, X_val)\n",
    "    y_prediction_train = predict(W, b, X_train)\n",
    "    lista = {\n",
    "        \"Ajuste entrenamiento\": 100 - np.mean(np.abs(y_prediction_train - y_train)) * 100,\n",
    "        \"Ajuste testeo\": 100 - np.mean(np.abs(y_prediction_validation - y_val)) * 100,\n",
    "        \"Costo en proceso\": costs\n",
    "    }\n",
    "    return lista\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
