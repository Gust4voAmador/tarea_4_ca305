{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "127e428b-b2a6-48db-bd06-9e4bb4cad419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def kernel_sigmoid(z):\n",
    "    '''\n",
    "    Función signomide o función logística, la cual tiene dominio en los \n",
    "    números reales e imágenes entre cero y uno.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    z (int): Cualqueir número real.\n",
    "    \n",
    "    Returns\n",
    "    ------    \n",
    "    (int): Número entre cero y uno.\n",
    "    '''    \n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "ea5314f0-9e62-4121-8425-9516d47569dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(W, b, X, y):\n",
    "    \"\"\"\n",
    "    Propagación hacia adelante, es dericr, calcula las predicciones del modelo y el costo asociado para un \n",
    "    conjunto dado de datos de entrada, utilizando los parámetros indicados W como peso y b como el sesgo.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    W (numpy.ndarray) : Vector de pesos de la regresión logística.\n",
    "        \n",
    "    b (float) : Sesgo de la regresión logística.\n",
    "        \n",
    "    X (numpy.ndarray): \n",
    "        Parámetro con la matriz de la variables caracteristicas. Cada fila representa una observacion, \n",
    "        y cada columna representa una variable (característica), es utilizado para trianing.\n",
    "        \n",
    "    y (numpy.ndarray) : Array de numpy (columna) con las estiquestas reales de los datos.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    A (numpy.ndarray): Array de numpy con las predicciones del modelo. Cada elemento del array representa la probabilidad\n",
    "    de que el ejemplo correspondiente pertenezca a la clase positiva (una de las dos etiquetas reales).\n",
    "\n",
    "        \n",
    "    cost (float) : Valor de la función de costo calculado.\n",
    "    \"\"\"  \n",
    "    \n",
    "    #obtener el número de filas de los datos de training\n",
    "    data_number = X.shape[0]\n",
    "    # Calcula para cada entrada de X un combinación linea con los parámetros de la regresión W y b\n",
    "    Z = np.dot(W, X.T) + b\n",
    "    # Aplicar la función sigmoide a cada valor de z para obtener las predicciones\n",
    "    A = kernel_sigmoid(Z)\n",
    "    # Calculo de la funcion de costos de la regresion. Sirve para medir que tan equivocado estás\n",
    "    cost = (- 1 / data_number) * np.sum(y * np.log(A) + (1 - y) * (np.log(1 - A)))\n",
    "    #Retorna las predicciones del modelo y el costo asociado con esas predicciones. \n",
    "    return A, cost\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "e079a2e9-a493-4f75-bf3f-9a33825fc10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(X, A, y):\n",
    "    \"\"\"\n",
    "    Se encargar de culcular los gredientes de parámetro W (peso) y b (sesgo), pasa así optimizar el costo del modelo.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X (numpy.ndarray): Parámetro con la matriz de la variables caracteristicas. Cada fila representa una observacion, \n",
    "        y cada columna representa una variable (característica).\n",
    "    A (numpy.ndarray): Valores predichos de la propagación hacia adelante.\n",
    "    y (numpy.ndarray): Array de numpy (columna) con las estiquestas reales de los datos.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dW (numpy.ndarray): Gradiente de la matriz de pesos.\n",
    "    db (float): Gradiente del sesgo.\n",
    "    \"\"\"\n",
    "    \n",
    "    #obtener el número de filas de los datos de training\n",
    "    data_number = X.shape[0]\n",
    "    # los gradites indica la dirección y la magnitud en la que debemos ajustar los parámetros\n",
    "    #Calcula el gradiente del array W (pesos) para minimizar el costo\n",
    "    dW = (1 / data_number) * np.dot((A - y), X)\n",
    "    #Calcula el gradiente del array b (sesgo) para minimizar el costo\n",
    "    db = (1 / data_number) * np.sum(A - y)\n",
    "    #Devuelve los gradites respectivos\n",
    "    return dW, db\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "c3633d23-8142-4bd6-84d7-eeedaaff39e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(W, b, X, y, num_iterations, learning_rate):\n",
    "    \"\"\"\n",
    "    El método optimize ajusta iterativamente los parámetros del modelo utilizando el gradiente \n",
    "    descendente para minimizar el costo. Guarda los costos cada 100 iteraciones permite monitorear\n",
    "    el proceso de entrenamiento y asegurarse de que el modelo está aprendiendo correctamente.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    W (numpy.ndarray): Vector de pesos de la regresión logística.\n",
    "    b (float): Valor de sesgo.\n",
    "    X (numpy.ndarray): Parámetro con la matriz de la variables caracteristicas. Cada fila representa una observacion, \n",
    "                       y cada columna representa una variable (característica).\n",
    "    y (numpy.ndarray): Array de numpy (columna) con las estiquestas reales de los datos.\n",
    "    num_iterations (int): Número de iteraciones para el bucle de optimización.\n",
    "    learning_rate (float): Tasa de aprendizaje para el descenso de gradiente.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    params (dict): Diccionario que contiene los W (pesos) y el b (sesgo) optimizados.\n",
    "    gradients (dict): Diccionario que contiene los gradientes finales de los pesos y el sesgo.\n",
    "    costs (list): Lista de costos registrados durante el proceso de optimización.\n",
    "    \"\"\"\n",
    "    #crea lista para guardar los costos.\n",
    "    costs = []\n",
    "\n",
    "    # For para ejecutar las actualizaciones segun el número de iteraciones especificado\n",
    "    for i in range(num_iterations):\n",
    "        #se ejecuta el metodo de propagacion hacia adelante con los parámetros ingresados\n",
    "        A, cost = forward_propagation(W, b, X, y)\n",
    "        #se ejecuta el metodo de propagacion hacia atras con los parámetros ingresados\n",
    "        dW, db = backward_propagation(X, A, y)\n",
    "        #Se modifica W con la tasa de aprendizaje indicada y el gradiente de W\n",
    "        W = W - learning_rate * dW\n",
    "        #Se modifica b con la tasa de aprendizaje indicada y el gradiente de b\n",
    "        b = b - learning_rate * db\n",
    "        #si la iteración es módulo 100 se guarda en la lista costs definida fura del for\n",
    "        #Esto para ver con se va comportando los costos y si van disminuyendo o si se estancó.\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "\n",
    "    #Diccionario para guardar los valores finales de los parámetros\n",
    "    params = {\n",
    "        \"W\": W, \n",
    "        \"b\": b\n",
    "    }\n",
    "    #Diccionario para guardar los valores finales de los gradientes\n",
    "    gradients = {\n",
    "        \"dW\": dW,\n",
    "        \"db\": db\n",
    "    }\n",
    "    #Devolver los diccionarios de los parámetros, gradientes y la lista de la evolución de los costos.\n",
    "    return params, gradients, costs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "9d67eab4-9164-437a-9ef1-546cc21afc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(W, b, X):\n",
    "    \"\"\"\n",
    "    Este método realiza predicciones utilizando los pesos y el sesgo que aprendió.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    W (numpy.ndarray): Vector de pesos de la regresión logística.\n",
    "    b (float): Valor de sesgo.\n",
    "    X (numpy.ndarray): Parámetro con la matriz de la variables caracteristicas. Cada fila representa una observacion, \n",
    "                       y cada columna representa una variable (característica)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    y_prediction (numpy.ndarray): Etiquetas predichas (valores 0 o 1).\n",
    "    \"\"\"   \n",
    "    #obtener el número de filas de los datos de training\n",
    "    data_number = X.shape[0]\n",
    "     #Inicializa un array a cero donde van a estar la predicciónes.\n",
    "    y_prediction = np.zeros((1, data_number))\n",
    "    # Calcula para cada entrada de X un combinación linea con los parámetros de la regresión W y b\n",
    "    Z = np.dot(W, X.T) + b\n",
    "    #aplica la función sigmoide en Z calculado anteriormente, obteniendo así las \"activaciones\" para cada entrada.\n",
    "    A = kernel_sigmoid(Z)\n",
    "    #for que recorre las activaciones de Z para generar las respectivas predicciones\n",
    "    for i in range(A.shape[1]):\n",
    "        #Es 1 cuando la activación es mayor que 0.5, sino se le asígna 0.\n",
    "        y_prediction[0, i] = 1 if A[0, i] > 0.5 else 0\n",
    "        \n",
    "    #Retorna todas las predicciones\n",
    "    return y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "e4bcaff9-e949-425a-bb3f-9d244c85cedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_regresion_logistico(X_train, y_train, X_val, y_val, num_iterations=2000, learning_rate=0.5):\n",
    "    \"\"\"\n",
    "    Método que entrena un modelo de regresión logística y lo evalúa en los datos de entrenamiento y validación.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train (numpy.ndarray): Partición de características seleccionadas para entrenamiento.\n",
    "    y_train (numpy.ndarray): Partición para entrenamiento.\n",
    "    X_val (numpy.ndarray): Partición de características para validación (testing).\n",
    "    y_val (numpy.ndarray): Particioón para validación (testing).\n",
    "    num_iterations (int): Número de iteraciones para el entrenamiento.\n",
    "    learning_rate (float): Tasa de aprendizaje para el descenso de gradiente.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    resultados (dict): Diccionario que contiene la precisión en entrenamiento, la precisión en validación y el historial de los costos.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Determinar el número de características\n",
    "    dimensions = X_train.shape[1]\n",
    "    # Inicializar los pesos y el sesgo a cero\n",
    "    W = np.zeros(shape=(1, dimensions))\n",
    "    b = 0\n",
    "    \n",
    "    # Optimizar los parámetros W y b utilizando los datos de entrenamiento\n",
    "    params, gradients, costs = optimize(W, b, X_train, y_train, num_iterations, learning_rate)\n",
    "    \n",
    "    # Obtener los valores optimizados de W y b\n",
    "    W = params[\"W\"]\n",
    "    b = params[\"b\"]\n",
    "    \n",
    "    # Realizar predicciones en los datos de entrenamiento y validación\n",
    "    y_prediction_train = predict(W, b, X_train)\n",
    "    y_prediction_validation = predict(W, b, X_val)\n",
    "    \n",
    "    # Calcular el ajuste (precisión) del modelo en los datos de entrenamiento y validación\n",
    "    ajuste_entrenamiento = 100 - np.mean(np.abs(y_prediction_train - y_train)) * 100\n",
    "    ajuste_val = 100 - np.mean(np.abs(y_prediction_validation - y_val)) * 100\n",
    "    \n",
    "    # Crear un diccionario con los resultados\n",
    "    resultados = {\n",
    "        \"Ajuste entrenamiento\": ajuste_entrenamiento,\n",
    "        \"Ajuste testeo\": ajuste_val,\n",
    "        \"Costo en proceso\": costs\n",
    "    }\n",
    "    \n",
    "    # Retornar el diccionario con los resultados\n",
    "    return resultados\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa078138-b8ea-407c-a995-f3968f710f28",
   "metadata": {},
   "source": [
    "# Ejecución de las 10 corridas del código"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09520592-5bd5-4c83-8343-320be2943ec1",
   "metadata": {},
   "source": [
    "## Código Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "e69897be-dde2-433a-a76e-62eeaed5a75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Run</th>\n",
       "      <th>Original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.048993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.049001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.051001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.050002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.046000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.055002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.046000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.045001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.053063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Run  Original\n",
       "0    1  0.048993\n",
       "1    2  0.049001\n",
       "2    3  0.051001\n",
       "3    4  0.050002\n",
       "4    5  0.050000\n",
       "5    6  0.046000\n",
       "6    7  0.055002\n",
       "7    8  0.046000\n",
       "8    9  0.045001\n",
       "9   10  0.053063"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "def kernel_sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def forward_propagation(W, b, X, y):\n",
    "    data_number = X.shape[0]\n",
    "    Z = np.dot(W, X.T) + b\n",
    "    A = kernel_sigmoid(Z)\n",
    "    cost = (-1 / data_number) * np.sum(y * np.log(A) + (1 - y) * (np.log(1 - A)))\n",
    "    return A, cost\n",
    "\n",
    "def backward_propagation(X, A, y):\n",
    "    data_number = X.shape[0]\n",
    "    dW = (1 / data_number) * np.dot((A - y), X)\n",
    "    db = (1 / data_number) * np.sum(A - y)\n",
    "    return dW, db\n",
    "\n",
    "def optimize(W, b, X, y, num_iterations, learning_rate):\n",
    "    costs = []\n",
    "    for i in range(num_iterations):\n",
    "        A, cost = forward_propagation(W, b, X, y)\n",
    "        dW, db = backward_propagation(X, A, y)\n",
    "        W = W - learning_rate * dW\n",
    "        b = b - learning_rate * db\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "    params = {\"W\": W, \"b\": b}\n",
    "    gradients = {\"dW\": dW, \"db\": db}\n",
    "    return params, gradients, costs\n",
    "\n",
    "def predict(W, b, X):\n",
    "    Z = np.dot(W, X.T) + b\n",
    "    A = kernel_sigmoid(Z)\n",
    "    y_prediction = (A > 0.5).astype(int)\n",
    "    return y_prediction\n",
    "\n",
    "def model_regresion_logistico1(X_train, y_train, X_val, y_val, num_iterations=2000, learning_rate=0.5):\n",
    "    dimensions = X_train.shape[1]\n",
    "    W = np.zeros((1, dimensions))\n",
    "    b = 0\n",
    "    params, gradients, costs = optimize(W, b, X_train, y_train, num_iterations, learning_rate)\n",
    "    W = params[\"W\"]\n",
    "    b = params[\"b\"]\n",
    "    \n",
    "    y_prediction_train = predict(W, b, X_train)\n",
    "    y_prediction_validation = predict(W, b, X_val)\n",
    "    \n",
    "    lista = {\n",
    "        \"Ajuste entrenamiento\": 100 - np.mean(np.abs(y_prediction_train - y_train)) * 100,\n",
    "        \"Ajuste testeo\": 100 - np.mean(np.abs(y_prediction_validation - y_val)) * 100,\n",
    "        \"Costo en proceso\": costs\n",
    "    }\n",
    "    return lista\n",
    "\n",
    "# Datos y las transformaciones\n",
    "datos = pd.read_csv(\"Diabetes.txt\")\n",
    "X = np.array(datos.drop([\"Outcome\"], axis=1))\n",
    "y = np.array(datos[\"Outcome\"])\n",
    "X = (X - np.min(X)) / (np.max(X) - np.min(X))\n",
    "\n",
    "# Separa la muestra\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=None)\n",
    "\n",
    "# Medir el tiempo de las 10 ejecuciones\n",
    "tiempos_ori = []\n",
    "for i in range(10):\n",
    "    inicio = time.time()\n",
    "    model_regresion_logistico1(X_train, y_train, X_val, y_val, num_iterations=1000, learning_rate=0.003)\n",
    "    fin = time.time()\n",
    "    tiempos_ori.append((i + 1, fin - inicio))\n",
    "\n",
    "tiempos_original = pd.DataFrame({\n",
    "    \"Run\": [tiempo[0] for tiempo in tiempos_ori],\n",
    "    \"Original\": [tiempo[1] for tiempo in tiempos_ori]\n",
    "})\n",
    "\n",
    "tiempos_original\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a80f6cb-c73b-4d6c-bae8-eaad1daed418",
   "metadata": {},
   "source": [
    "## Optimizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "598877f9-5388-420d-9cbb-f3ab70446d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Run</th>\n",
       "      <th>Optimizado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.046000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.048049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.041368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.041913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.043002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.040827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.049999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.039003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.038052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.039947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Run  Optimizado\n",
       "0    1    0.046000\n",
       "1    2    0.048049\n",
       "2    3    0.041368\n",
       "3    4    0.041913\n",
       "4    5    0.043002\n",
       "5    6    0.040827\n",
       "6    7    0.049999\n",
       "7    8    0.039003\n",
       "8    9    0.038052\n",
       "9   10    0.039947"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def model_regresion_logistico2(X_train, y_train, X_val, y_val, num_iterations=1000, learning_rate=0.01, batch_size=64):\n",
    "    dimensions = X_train.shape[1]\n",
    "    W = np.zeros(dimensions)\n",
    "    b = 0\n",
    "    data_number = X_train.shape[0]\n",
    "    \n",
    "    costs = []\n",
    "    for i in range(num_iterations):\n",
    "        Z = np.dot(X_train, W) + b\n",
    "        A = sigmoid(Z)\n",
    "        \n",
    "        cost = (-1 / data_number) * np.sum(y_train * np.log(A) + (1 - y_train) * np.log(1 - A))\n",
    "        \n",
    "        dW = (1 / data_number) * np.dot(X_train.T, (A - y_train))\n",
    "        db = (1 / data_number) * np.sum(A - y_train)\n",
    "        \n",
    "        W -= learning_rate * dW\n",
    "        b -= learning_rate * db\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "\n",
    "    #precalcalcular parámetros de la funcion\n",
    "    Z_train = np.dot(X_train, W) + b\n",
    "    Z_val = np.dot(X_val, W) + b\n",
    "    #Y luego vectorizar la función predicción evitando un ciclo for\n",
    "    y_prediction_train = sigmoid(Z_train) >= 0.5\n",
    "    y_prediction_validation = sigmoid(Z_val) >= 0.5\n",
    "    \n",
    "    #No usar diccionario y ejecutar las operaciones y resultados en el return\n",
    "    return 100 - np.mean(np.abs(y_prediction_train - y_train)) * 100, 100 - np.mean(np.abs(y_prediction_validation - y_val)) * 100, costs\n",
    "\n",
    "# Datos y las transformaciones\n",
    "datos = pd.read_csv(\"Diabetes.txt\")\n",
    "X = np.array(datos.drop([\"Outcome\"], axis=1))\n",
    "y = np.array(datos[\"Outcome\"])\n",
    "X = (X - np.min(X, axis=0)) / (np.max(X, axis=0) - np.min(X, axis=0))\n",
    "\n",
    "# Separa la muestra\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=None)\n",
    "\n",
    "# Medir el tiempo de las 10 ejecuciones\n",
    "tiempos_opti = []\n",
    "for i in range(10):\n",
    "    inicio = time.time()\n",
    "    ajuste_entrenamiento, ajuste_testeo, costs = model_regresion_logistico2(X_train, y_train, X_val, y_val, num_iterations=1000, learning_rate=0.01)\n",
    "    fin = time.time()\n",
    "    tiempos_opti.append((i + 1, fin - inicio))\n",
    "\n",
    "tiempos_optimizado = pd.DataFrame({\n",
    "    \"Run\": [tiempo[0] for tiempo in tiempos_opti],\n",
    "    \"Optimizado\": [tiempo[1] for tiempo in tiempos_opti]\n",
    "})\n",
    "\n",
    "tiempos_optimizado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498a9a23-fa7e-4188-a240-88584581828c",
   "metadata": {},
   "source": [
    "## Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "5ffd0cfa-d197-464d-9342-44c9468e4a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Run</th>\n",
       "      <th>Sklearn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.002962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.002078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.003920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.002048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.002953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.002047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.003007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.002945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.001999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.003000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Run   Sklearn\n",
       "0    1  0.002962\n",
       "1    2  0.002078\n",
       "2    3  0.003920\n",
       "3    4  0.002048\n",
       "4    5  0.002953\n",
       "5    6  0.002047\n",
       "6    7  0.003007\n",
       "7    8  0.002945\n",
       "8    9  0.001999\n",
       "9   10  0.003000"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# Datos y transformaciones\n",
    "datos = pd.read_csv(\"Diabetes.txt\")\n",
    "X = np.array(datos.drop([\"Outcome\"], axis=1))\n",
    "y = np.array(datos[\"Outcome\"])\n",
    "X = (X - np.min(X)) / (np.max(X) - np.min(X))\n",
    "\n",
    "# Separa la muestra\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Medir tiempo del modelo LogisticRegression en 10 ejecuciones\n",
    "tiempos_sklearn = []\n",
    "for i in range(10):\n",
    "    inicio = time.time()\n",
    "    modelo = LogisticRegression(max_iter=1000)\n",
    "    modelo.fit(X_train, y_train)\n",
    "    fin = time.time()\n",
    "    tiempos_sklearn.append((i + 1, fin - inicio))\n",
    "\n",
    "# Resultados\n",
    "tiempos_sklearn = pd.DataFrame({\n",
    "    \"Run\": [tiempo[0] for tiempo in tiempos_sklearn],\n",
    "    \"Sklearn\": [tiempo[1] for tiempo in tiempos_sklearn]\n",
    "})\n",
    "\n",
    "tiempos_sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ac78be-d74f-4583-8c08-8141a4d9d767",
   "metadata": {},
   "source": [
    "## Tabla Resumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "9dda6eb2-e9cb-487b-8c01-433ecaa55cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Run</th>\n",
       "      <th>Original</th>\n",
       "      <th>Optimizado</th>\n",
       "      <th>Sklearn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.048993</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>0.002962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.049001</td>\n",
       "      <td>0.048049</td>\n",
       "      <td>0.002078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.051001</td>\n",
       "      <td>0.041368</td>\n",
       "      <td>0.003920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.050002</td>\n",
       "      <td>0.041913</td>\n",
       "      <td>0.002048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.043002</td>\n",
       "      <td>0.002953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>0.040827</td>\n",
       "      <td>0.002047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.055002</td>\n",
       "      <td>0.049999</td>\n",
       "      <td>0.003007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>0.039003</td>\n",
       "      <td>0.002945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.045001</td>\n",
       "      <td>0.038052</td>\n",
       "      <td>0.001999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.053063</td>\n",
       "      <td>0.039947</td>\n",
       "      <td>0.003000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Media</td>\n",
       "      <td>0.049406</td>\n",
       "      <td>0.042816</td>\n",
       "      <td>0.002696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Run  Original  Optimizado   Sklearn\n",
       "0       1  0.048993    0.046000  0.002962\n",
       "1       2  0.049001    0.048049  0.002078\n",
       "2       3  0.051001    0.041368  0.003920\n",
       "3       4  0.050002    0.041913  0.002048\n",
       "4       5  0.050000    0.043002  0.002953\n",
       "5       6  0.046000    0.040827  0.002047\n",
       "6       7  0.055002    0.049999  0.003007\n",
       "7       8  0.046000    0.039003  0.002945\n",
       "8       9  0.045001    0.038052  0.001999\n",
       "9      10  0.053063    0.039947  0.003000\n",
       "10  Media  0.049406    0.042816  0.002696"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extraer columnas de cada df de los tiempos de ejecución\n",
    "df1 = tiempos_original[['Run', 'Original']]\n",
    "df2 = tiempos_optimizado[['Optimizado']]\n",
    "df3 = tiempos_sklearn[['Sklearn']]\n",
    "\n",
    "# Concatenar las columnas extraídas una al lado de la otra\n",
    "df_colums = pd.concat([df1, df2, df3], axis=1)\n",
    "\n",
    "# Crear observación promedio\n",
    "fila_prom = pd.DataFrame({\n",
    "    'Run': ['Media'],\n",
    "    'Original': [df1['Original'].mean()],\n",
    "    'Optimizado': [df2['Optimizado'].mean()],\n",
    "    'Sklearn': [df3['Sklearn'].mean()]\n",
    "})\n",
    "\n",
    "# Concatenar la fila de promedios al DataFrame\n",
    "df_resumen = pd.concat([df_colums, fila_prom], axis=0, ignore_index=True)\n",
    "\n",
    "df_resumen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70eef97b-a575-4f8e-a57d-dcf43a76cb42",
   "metadata": {},
   "source": [
    "\n",
    "### Conclusiones:\n",
    "    1. El tener mayor cantidad de funciónes puede ser mas \"ordenado\" pero es menos óptimo\n",
    "    2. Entre mas operaciones entre objetes de una misma librería haga es mejor, pues estos están optimizacos entre sí.\n",
    "    3. Vectorizar funciónes de ciclos disminuye de manera evidente el tiempo de ejecución\n",
    "    4. Las librería de modelos de python está muy optimizados las cuales es difícil crear un código con el tiempo de ejución que estos presentan.\n",
    "    5. Entre más iteraciones se pierde la ambiguedad del tiempo y muestra más claro de cual es más optimo que otro.\n",
    "\n",
    "\n",
    "### Modificaciones que redujerfon el tiempo:\n",
    "    1. Primero lo que hice fue reducir el número de métodos externos en el modelo final, no obstante si dejé algunas ya que quitarlas implicaba hacerlo más lento.\n",
    "    2. La función predict la sustituí completamente por una versión vectorizada y sin for, y también inicializaba variables que estaban dentro de for de estas desde afuera e ingresarla como parámetro para evitar su multiple declaración.\n",
    "    3. Se quitó el diccionario de return y se devolvió en vector los resultados y los cuales no se definieron anteriormente, sino que en el return."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
